{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, k=3, distance_metric='euclidean'):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "\n",
    "    def fit(self, X, y):\n",
    "       \n",
    "        self.X_train = np.array(X)\n",
    "        self.y_train = np.array(y)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \n",
    "        probs = []\n",
    "        for x in X_test:\n",
    "            distances = self.compute_distance(self.X_train, x)\n",
    "            k_idx = np.argsort(distances)[:self.k]\n",
    "            neighbor_labels = self.y_train[k_idx]\n",
    "            prob = sum(neighbor_labels) / self.k  \n",
    "            probs.append(prob)\n",
    "        \n",
    "        return probs\n",
    "\n",
    "    def compute_distance(self, X1, X2):\n",
    "    \n",
    "        if self.distance_metric == 'euclidean':\n",
    "            return np.sqrt(np.sum((X1 - X2) ** 2, axis=1))\n",
    "        elif self.distance_metric == 'manhattan':\n",
    "            return np.sum(np.abs(X1 - X2), axis=1)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown distance metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_path, test_path):\n",
    "    # Load datasets\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    # Feature lists\n",
    "    cat_feats = ['Geography', 'Gender']\n",
    "    num_feats = ['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']\n",
    "    ord_feats = ['NumOfProducts', 'HasCrCard', 'IsActiveMember']\n",
    "\n",
    "    # Standardize numerical features using training data statistics\n",
    "    num_train = train_df[num_feats].values\n",
    "    num_mean = num_train.mean(axis=0)\n",
    "    num_std = num_train.std(axis=0)\n",
    "    train_num = (num_train - num_mean) / num_std\n",
    "    test_num = (test_df[num_feats].values - num_mean) / num_std\n",
    "\n",
    "    # Standardize ordinal features using training data statistics\n",
    "    ord_train = train_df[ord_feats].values\n",
    "    ord_mean = ord_train.mean(axis=0)\n",
    "    ord_std = ord_train.std(axis=0)\n",
    "    train_ord = (ord_train - ord_mean) / ord_std\n",
    "    test_ord = (test_df[ord_feats].values - ord_mean) / ord_std\n",
    "\n",
    "    # One-hot encode categorical features using training data mappings\n",
    "    train_cat_arrays = []\n",
    "    test_cat_arrays = []\n",
    "    for feat in cat_feats:\n",
    "        vals = train_df[feat].unique()\n",
    "        mapping = {val: idx for idx, val in enumerate(vals)}\n",
    "        # Training data encoding\n",
    "        train_encoded = train_df[feat].map(mapping).values\n",
    "        train_one_hot = np.zeros((train_encoded.size, len(vals)))\n",
    "        train_one_hot[np.arange(train_encoded.size), train_encoded] = 1\n",
    "        train_cat_arrays.append(train_one_hot)\n",
    "        # Test data encoding\n",
    "        test_encoded = test_df[feat].map(mapping).fillna(-1).astype(int)\n",
    "        test_one_hot = np.zeros((test_encoded.size, len(vals)))\n",
    "        valid_idx = test_encoded >= 0\n",
    "        test_one_hot[np.arange(test_encoded.size)[valid_idx], test_encoded[valid_idx]] = 1\n",
    "        test_cat_arrays.append(test_one_hot)\n",
    "\n",
    "    train_cat = np.hstack(train_cat_arrays)\n",
    "    test_cat = np.hstack(test_cat_arrays)\n",
    "\n",
    "    # Combine features\n",
    "    train_X = np.hstack([train_num, train_ord, train_cat])\n",
    "    test_X = np.hstack([test_num, test_ord, test_cat])\n",
    "\n",
    "    # Extract labels\n",
    "    train_y = train_df['Exited'].values\n",
    "\n",
    "    return train_X, train_y, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(X, y, knn, n_splits=5):\n",
    "\n",
    "    idx = np.random.permutation(len(X))\n",
    "    fold_size = len(X) // n_splits\n",
    "    auc_list = []\n",
    "\n",
    "    for i in range(n_splits):\n",
    "        test_idx = idx[i * fold_size:(i + 1) * fold_size]\n",
    "        train_idx = np.setdiff1d(idx, test_idx)\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        knn.fit(X_train, y_train)\n",
    "\n",
    "        y_scores = []\n",
    "        for x in X_test:\n",
    "            dists = knn.compute_distance(knn.X_train, x)\n",
    "            k_idx = np.argsort(dists)[:knn.k]\n",
    "            k_labels = knn.y_train[k_idx]\n",
    "            prob = np.sum(k_labels) / knn.k\n",
    "            y_scores.append(prob)\n",
    "\n",
    "        # Compute ROC AUC score\n",
    "        y_true = np.array(y_test)\n",
    "        y_score = np.array(y_scores)\n",
    "        sort_idx = np.argsort(y_score)[::-1]\n",
    "        y_true = y_true[sort_idx]\n",
    "        y_score = y_score[sort_idx]\n",
    "\n",
    "        diffs = np.where(np.diff(y_score))[0]\n",
    "        last_idx = np.array([len(y_true) - 1])\n",
    "        thresh = np.hstack((diffs, last_idx))\n",
    "\n",
    "        tps = np.cumsum(y_true)[thresh]\n",
    "        fps = (1 + thresh) - tps\n",
    "\n",
    "        tpr = tps / tps[-1]\n",
    "        fpr = fps / fps[-1]\n",
    "\n",
    "        zero = np.array([0])\n",
    "        tpr_diff = np.hstack((np.diff(tpr), zero))\n",
    "        fpr_diff = np.hstack((np.diff(fpr), zero))\n",
    "        auc = np.dot(tpr, fpr_diff) + np.dot(tpr_diff, fpr_diff) / 2\n",
    "        auc_list.append(auc)\n",
    "\n",
    "    return np.mean(auc_list)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating: k=45, metric=euclidean\n",
      "CV Score for k=45, metric=euclidean: 0.9120\n",
      "\n",
      "Evaluating: k=45, metric=manhattan\n",
      "CV Score for k=45, metric=manhattan: 0.9095\n",
      "\n",
      "Evaluating: k=50, metric=euclidean\n",
      "CV Score for k=50, metric=euclidean: 0.9130\n",
      "\n",
      "Evaluating: k=50, metric=manhattan\n",
      "CV Score for k=50, metric=manhattan: 0.9103\n",
      "\n",
      "Evaluating: k=55, metric=euclidean\n",
      "CV Score for k=55, metric=euclidean: 0.9119\n",
      "\n",
      "Evaluating: k=55, metric=manhattan\n",
      "CV Score for k=55, metric=manhattan: 0.9091\n",
      "\n",
      "Evaluating: k=60, metric=euclidean\n",
      "CV Score for k=60, metric=euclidean: 0.9131\n",
      "\n",
      "Evaluating: k=60, metric=manhattan\n",
      "CV Score for k=60, metric=manhattan: 0.9098\n",
      "\n",
      "Evaluating: k=65, metric=euclidean\n",
      "CV Score for k=65, metric=euclidean: 0.9122\n",
      "\n",
      "Evaluating: k=65, metric=manhattan\n",
      "CV Score for k=65, metric=manhattan: 0.9100\n",
      "\n",
      "Best KNN Parameters: k=60, Metric=euclidean with ROC AUC Score: 0.9131\n"
     ]
    }
   ],
   "source": [
    "X, y, X_test = preprocess_data('train.csv','test.csv')\n",
    "\n",
    "best_score = 0\n",
    "best_k = 0\n",
    "best_metric = ''\n",
    "\n",
    "for k in range(45,70,5):  \n",
    "    for metric in ['euclidean','manhattan']: \n",
    "        print(f\"\\nEvaluating: k={k}, metric={metric}\")\n",
    "\n",
    "        knn = KNN(k=k, distance_metric=metric)  \n",
    "        cv_score = cross_validate(X, y, knn, n_splits=5)  \n",
    "\n",
    "        print(f\"CV Score for k={k}, metric={metric}: {cv_score:.4f}\")\n",
    "\n",
    "        if cv_score > best_score:\n",
    "            best_score = cv_score\n",
    "            best_k = k\n",
    "            best_metric = metric\n",
    "\n",
    "print(f\"\\nBest KNN Parameters: k={best_k}, Metric={best_metric} with ROC AUC Score: {best_score:.4f}\")\n",
    "best_knn = KNN(k=best_k, distance_metric=best_metric)\n",
    "best_knn.fit(X, y)\n",
    "test_predictions = best_knn.predict(X_test)\n",
    "\n",
    "submission_df = pd.DataFrame({'id': pd.read_csv('test.csv')['id'], 'Exited': test_predictions})\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
